name: ğŸ“‚ ×ª××œ×•×œ ×§×•×‘×¥ ××”×¤×¨×•×™×§×˜

on:
  workflow_dispatch:
    inputs:
      file_name:
        description: '×©× ×”×§×•×‘×¥ ×‘×ª×™×§×™×™×ª audio (×œ××©×œ: myfile.mp3)'
        required: true
        type: string
      model_size:
        description: '×’×•×“×œ ××•×“×œ'
        required: true
        default: 'base'
        type: choice
        options:
          - tiny
          - base
          - small
          - medium

jobs:
  transcribe:
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        lfs: true  # ×× ××©×ª××©×™× ×‘-Git LFS ×œ×§×‘×¦×™× ×’×“×•×œ×™×
    
    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: ğŸµ Install FFmpeg
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg
    
    - name: ğŸ“¦ Install Whisper
      run: |
        pip install --upgrade pip
        pip install openai-whisper
    
    - name: ğŸ” ×‘×“×™×§×ª ×§×•×‘×¥
      run: |
        FILE_PATH="audio/${{ inputs.file_name }}"
        
        echo "ğŸ” ××—×¤×© ××ª: $FILE_PATH"
        
        if [ ! -f "$FILE_PATH" ]; then
          echo "âŒ ×”×§×•×‘×¥ ×œ× × ××¦×!"
          echo ""
          echo "ğŸ“ ×§×‘×¦×™× ×–××™× ×™× ×‘×ª×™×§×™×™×ª audio:"
          ls -la audio/ 2>/dev/null || echo "×”×ª×™×§×™×™×” audio ×œ× ×§×™×™××ª"
          echo ""
          echo "ğŸ’¡ ×•×“× ×©:"
          echo "1. ×”×§×•×‘×¥ × ××¦× ×‘×ª×™×§×™×™×ª audio/"
          echo "2. ×”×©× × ×›×ª×‘ × ×›×•×Ÿ (×›×•×œ×œ ×¡×™×•××ª)"
          echo "3. ×¢×©×™×ª Commit ××—×¨×™ ×”×¢×œ××ª ×”×§×•×‘×¥"
          exit 1
        fi
        
        echo "âœ… ×”×§×•×‘×¥ × ××¦×!"
        echo "ğŸ“Š ×¤×¨×˜×™ ×”×§×•×‘×¥:"
        ls -lh "$FILE_PATH"
        file "$FILE_PATH"
        
        # ×‘×“×•×§ ×¢× ffprobe
        echo ""
        echo "ğŸµ ××™×“×¢ ×¢×œ ×”××•×“×™×•:"
        ffprobe -v error -show_format -show_streams "$FILE_PATH" 2>&1 | head -20
    
    - name: ğŸ™ï¸ ×ª××œ×•×œ
      env:
        FILE_NAME: ${{ inputs.file_name }}
        MODEL_SIZE: ${{ inputs.model_size }}
      run: |
        python << 'EOF'
        import whisper
        import json
        import os
        from datetime import datetime
        
        # ×”×’×“×¨×•×ª
        file_path = f"audio/{os.environ['FILE_NAME']}"
        model_size = os.environ.get('MODEL_SIZE', 'base')
        
        print(f"ğŸ”„ ×˜×•×¢×Ÿ ××•×“×œ {model_size}...")
        model = whisper.load_model(model_size)
        
        print(f"ğŸ™ï¸ ××ª××œ×œ ××ª {file_path}...")
        
        # ×ª××œ×œ
        result = model.transcribe(file_path, language="he", verbose=False)
        
        # ×©× ×‘×¡×™×¡ ×œ×§×‘×¦×™ ×¤×œ×˜
        base_name = os.path.splitext(os.environ['FILE_NAME'])[0]
        
        # ×©××•×¨ ×˜×§×¡×˜
        with open(f"{base_name}_transcription.txt", "w", encoding="utf-8") as f:
            f.write(f"×ª××œ×•×œ ×©×œ: {file_path}\n")
            f.write(f"×ª××¨×™×š: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
            f.write(f"××•×“×œ: {model_size}\n")
            f.write("="*50 + "\n\n")
            f.write(result["text"])
        
        # ×©××•×¨ JSON
        metadata = {
            "file": file_path,
            "date": datetime.now().isoformat(),
            "model": model_size,
            "language": "Hebrew",
            "duration": result.get("duration", 0),
            "text": result["text"],
            "segments": result["segments"]
        }
        
        with open(f"{base_name}_data.json", "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # ×¦×•×¨ ×›×ª×•×‘×™×•×ª SRT
        with open(f"{base_name}_subtitles.srt", "w", encoding="utf-8") as f:
            for i, segment in enumerate(result["segments"], 1):
                start = f"{int(segment['start']//3600):02d}:{int(segment['start']%3600//60):02d}:{segment['start']%60:06.3f}".replace(".", ",")
                end = f"{int(segment['end']//3600):02d}:{int(segment['end']%3600//60):02d}:{segment['end']%60:06.3f}".replace(".", ",")
                f.write(f"{i}\n{start} --> {end}\n{segment['text'].strip()}\n\n")
        
        print("\nâœ… ×”×ª××œ×•×œ ×”×•×©×œ× ×‘×”×¦×œ×—×”!")
        print(f"ğŸ“Š ××©×š: {result.get('duration', 0):.1f} ×©× ×™×•×ª")
        print(f"ğŸ“ ××™×œ×™×: {len(result['text'].split())}")
        
        # ×ª×¦×•×’×” ××§×“×™××”
        print("\nğŸ“ ×ª×¦×•×’×” ××§×“×™××”:")
        print("-" * 50)
        preview = result["text"][:300] + "..." if len(result["text"]) > 300 else result["text"]
        print(preview)
        EOF
    
    - name: ğŸ“¤ ×”×¢×œ××ª ×ª×•×¦××•×ª
      uses: actions/upload-artifact@v4
      with:
        name: ×ª××œ×•×œ-${{ inputs.file_name }}-${{ github.run_number }}
        path: |
          *_transcription.txt
          *_subtitles.srt
          *_data.json
