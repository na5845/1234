name: ğŸ¥ ×ª××œ×•×œ ×¡×¨×˜×•×Ÿ YouTube

on:
  workflow_dispatch:
    inputs:
      youtube_url:
        description: '×§×™×©×•×¨ YouTube'
        required: true
        type: string
        placeholder: 'https://www.youtube.com/watch?v=...'
      model_size:
        description: '×’×•×“×œ ××•×“×œ Whisper'
        required: true
        default: 'base'
        type: choice
        options:
          - tiny
          - base
          - small
          - medium
      quality:
        description: '××™×›×•×ª ××•×“×™×•'
        required: true
        default: 'best'
        type: choice
        options:
          - best
          - good
          - worst

jobs:
  transcribe-youtube:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
    - name: ğŸ“¥ Checkout
      uses: actions/checkout@v4
      
    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: ğŸ“¦ Install dependencies
      run: |
        pip install --upgrade pip
        pip install openai-whisper yt-dlp
        
    - name: ğŸ“Š Get video info
      id: video_info
      run: |
        echo "ğŸ” ××§×‘×œ ××™×“×¢ ×¢×œ ×”×¡×¨×˜×•×Ÿ..."
        
        # ×§×‘×œ ××™×“×¢ ×‘×œ×‘×“ (×‘×œ×™ ×œ×”×•×¨×™×“)
        yt-dlp --print "%(title)s" "${{ inputs.youtube_url }}" > title.txt
        yt-dlp --print "%(duration)s" "${{ inputs.youtube_url }}" > duration.txt
        yt-dlp --print "%(uploader)s" "${{ inputs.youtube_url }}" > uploader.txt
        
        # ×©××•×¨ ×œ××©×ª× ×™×
        echo "title=$(cat title.txt)" >> $GITHUB_OUTPUT
        echo "duration=$(cat duration.txt)" >> $GITHUB_OUTPUT
        echo "uploader=$(cat uploader.txt)" >> $GITHUB_OUTPUT
        
        # ×”×¦×’ ××™×“×¢
        echo "ğŸ“¹ ×›×•×ª×¨×ª: $(cat title.txt)"
        echo "â±ï¸ ××©×š: $(cat duration.txt) ×©× ×™×•×ª"
        echo "ğŸ‘¤ ××¢×œ×”: $(cat uploader.txt)"
        
    - name: ğŸµ Download audio
      run: |
        echo "ğŸ“¥ ××•×¨×™×“ ××•×“×™×• ×-YouTube..."
        
        # ×”×’×“×¨ ××™×›×•×ª
        if [ "${{ inputs.quality }}" == "best" ]; then
          AUDIO_QUALITY="0"
        elif [ "${{ inputs.quality }}" == "good" ]; then
          AUDIO_QUALITY="5"
        else
          AUDIO_QUALITY="9"
        fi
        
        # ×”×•×¨×“ ×¨×§ ××•×“×™×•
        yt-dlp \
          -f "bestaudio/best" \
          -x \
          --audio-format mp3 \
          --audio-quality $AUDIO_QUALITY \
          -o "audio.%(ext)s" \
          "${{ inputs.youtube_url }}"
          
        # ×‘×“×•×§ ×’×•×“×œ
        ls -lh audio.mp3
        
    - name: ğŸ™ï¸ Transcribe
      run: |
        python << 'EOF'
        import whisper
        import json
        import os
        from datetime import datetime, timedelta
        
        # ×˜×¢×Ÿ ××•×“×œ
        model_size = "${{ inputs.model_size }}"
        print(f"ğŸ”„ ×˜×•×¢×Ÿ ××•×“×œ {model_size}...")
        model = whisper.load_model(model_size)
        
        # ×ª××œ×œ
        print("ğŸ™ï¸ ××ª×—×™×œ ×ª××œ×•×œ...")
        result = model.transcribe("audio.mp3", language="he", verbose=True)
        
        # ××™×“×¢ ×¢×œ ×”×¡×¨×˜×•×Ÿ
        video_info = {
            "url": "${{ inputs.youtube_url }}",
            "title": "${{ steps.video_info.outputs.title }}",
            "duration": int("${{ steps.video_info.outputs.duration }}"),
            "uploader": "${{ steps.video_info.outputs.uploader }}",
            "transcribed_at": datetime.now().isoformat()
        }
        
        # ×©××•×¨ ×˜×§×¡×˜ ××œ×
        with open("transcription.txt", "w", encoding="utf-8") as f:
            f.write(f"×ª××œ×•×œ: {video_info['title']}\n")
            f.write(f"×××ª: {video_info['uploader']}\n")
            f.write(f"××©×š: {timedelta(seconds=video_info['duration'])}\n")
            f.write("="*50 + "\n\n")
            f.write(result["text"])
        
        # ×©××•×¨ JSON ××¤×•×¨×˜
        full_result = {
            "video_info": video_info,
            "model": model_size,
            "text": result["text"],
            "segments": result["segments"]
        }
        
        with open("transcription.json", "w", encoding="utf-8") as f:
            json.dump(full_result, f, ensure_ascii=False, indent=2)
        
        # ×¦×•×¨ ×›×ª×•×‘×™×•×ª YouTube (×¤×•×¨××˜ ××™×•×—×“)
        with open("youtube_captions.sbv", "w", encoding="utf-8") as f:
            for segment in result["segments"]:
                start = timedelta(seconds=segment["start"])
                end = timedelta(seconds=segment["end"])
                
                # ×¤×•×¨××˜ SBV ×©×œ YouTube
                start_str = f"{int(start.total_seconds()//3600)}:{int(start.total_seconds()%3600//60):02d}:{start.total_seconds()%60:06.3f}"
                end_str = f"{int(end.total_seconds()//3600)}:{int(end.total_seconds()%3600//60):02d}:{end.total_seconds()%60:06.3f}"
                
                f.write(f"{start_str},{end_str}\n")
                f.write(f"{segment['text'].strip()}\n\n")
        
        # ×¦×•×¨ ×§×•×‘×¥ ×œ×ª×™××•×¨ YouTube
        with open("youtube_description.txt", "w", encoding="utf-8") as f:
            f.write("â±ï¸ ×—×•×ª××•×ª ×–××Ÿ:\n\n")
            
            # ×—×œ×§ ×œ×¤×¨×§×™× (×›×œ 5 ×“×§×•×ª ××• ×œ×¤×™ ×”×¤×¡×§×•×ª)
            chapters = []
            current_chapter_start = 0
            current_texts = []
            
            for segment in result["segments"]:
                current_texts.append(segment["text"])
                
                # ×× ×¢×‘×¨×• 5 ×“×§×•×ª ××• ×™×© ×”×¤×¡×§×” ××¨×•×›×”
                if segment["end"] - current_chapter_start > 300 or \
                   (len(chapters) > 0 and segment["start"] - result["segments"][result["segments"].index(segment)-1]["end"] > 5):
                    
                    # ×¡×›× ××ª ×”×¤×¨×§
                    chapter_text = " ".join(current_texts[:10])  # 10 ××™×œ×™× ×¨××©×•× ×•×ª
                    if len(chapter_text) > 50:
                        chapter_text = chapter_text[:50] + "..."
                    
                    timestamp = timedelta(seconds=current_chapter_start)
                    time_str = f"{int(timestamp.total_seconds()//60):02d}:{int(timestamp.total_seconds()%60):02d}"
                    
                    f.write(f"{time_str} - {chapter_text}\n")
                    
                    current_chapter_start = segment["start"]
                    current_texts = []
        
        print("\nâœ… ×”×ª××œ×•×œ ×”×•×©×œ×!")
        print(f"ğŸ“ ××™×œ×™×: {len(result['text'].split())}")
        print(f"ğŸ¬ ×¤×œ×—×™×: {len(result['segments'])}")
        
        EOF
        
    - name: ğŸ“¤ Upload results
      uses: actions/upload-artifact@v3
      with:
        name: youtube-transcription-${{ github.run_number }}
        path: |
          transcription.txt
          transcription.json
          youtube_captions.sbv
          youtube_description.txt
          
    - name: ğŸ’¬ Create summary comment
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          
          // ×§×¨× ××ª ×”×ª××œ×•×œ
          const transcription = fs.readFileSync('transcription.txt', 'utf8');
          const lines = transcription.split('\n');
          
          // ×¦×•×¨ ×ª×§×¦×™×¨
          const preview = lines.slice(4, 10).join('\n');
          
          // ×¦×•×¨ ×”×•×“×¢×”
          const body = `## ğŸ¥ ×ª××œ×•×œ ×”×•×©×œ×!
          
          **×¡×¨×˜×•×Ÿ:** ${{ steps.video_info.outputs.title }}
          **××©×š:** ${Math.floor(${{ steps.video_info.outputs.duration }}/60)} ×“×§×•×ª
          **××•×“×œ:** ${{ inputs.model_size }}
          
          ### ğŸ“ ×ª×¦×•×’×” ××§×“×™××”:
          \`\`\`
          ${preview}...
          \`\`\`
          
          ### ğŸ“¥ ×”×•×¨×“×•×ª:
          - ×œ×š ×œ-[Artifacts](../actions/runs/${{ github.run_id }}) ×œ×”×•×¨×“×ª ×”×§×‘×¦×™× ×”××œ××™×
          - ×›×•×œ×œ: ×˜×§×¡×˜ ××œ×, ×›×ª×•×‘×™×•×ª, ×—×•×ª××•×ª ×–××Ÿ
          `;
          
          // ×× ×–×” pull request, ×”×•×¡×£ ×ª×’×•×‘×”
          if (context.payload.pull_request) {
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
          }
